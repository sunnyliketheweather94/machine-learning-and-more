{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39951dac",
   "metadata": {},
   "source": [
    "## Utility Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fd5b8",
   "metadata": {},
   "source": [
    "### Job-Hopping and Wages-Utility-Maximization:      \n",
    "You are a worker who starts every day either employed or unemployed. If you start your day employed, you work on your job for the day (one of $n$ jobs, as elaborated later) and you get to earn the wage of the job for the day. However, at the end of the day, you could lose your job with probability $\\alpha \\in [0,1]$, in which case you start the next day unemployed. If at the end of the day, you do not lose your job (with probability $1-\\alpha$), then you will start the next day with the same job (and hence, the same daily wage). On the other hand, if you start your day unemployed, then you will be randomly offered one of $n$ jobs with daily wages $w_1, w_2, \\ldots w_n \\in \\mathbb{R}^+$ with respective job-offer probabilities $p_1, p_2, \\ldots p_n \\in [0,1]$ (with $\\sum_{i=1}^n p_i = 1$). You can choose to either accept or decline the offered job. If you accept the job-offer, your day progresses exactly like the {\\em employed-day} described above (earning the day's job wage and possibly (with probability $\\alpha$) losing the job at the end of the day). However, if you decline the job-offer, you spend the day unemployed, receive the unemployment wage $w_0 \\in \\mathbb{R}^+$ for the day, and start the next day unemployed. The problem is to identify the optimal choice of accepting or rejecting any of the job-offers the worker receives, in a manner that maximizes the infinite-horizon {\\em Expected Discounted-Sum of Wages Utility}. Assume the daily discount factor for wages (employed or unemployed) is $\\gamma \\in [0,1)$. Assume Wages Utility function to be $U(w) = \\log(w)$ for any wage amount $w \\in \\mathbb{R}^+$. So you are looking to maximize \n",
    "$$\n",
    "\\mathbb{E}[\\Sigma_{u=t}^\\infty \\gamma^{u-t} \\cdot \\log(w_{i_u})]\n",
    "$$ \n",
    "at the start of a given day $t$ ($w_{i_u}$ is the wage earned on day $u$, $0\\leq i_u \\leq n$ for all $u\\geq t$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d040f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a205886",
   "metadata": {},
   "source": [
    "#### Question 1:      \n",
    "Express with clear mathematical notation the state space, action space, transition function, reward function, and write the Bellman Optimality Equation customized for this MDP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1931542",
   "metadata": {},
   "source": [
    "The state space is the set $\\mathcal{S} = \\left\\{ 0, 1, 2, ..., n\\right\\}$, where 0 = the unemployed state, and $n$ = number of jobs available.         \n",
    "The action space is the set $\\mathcal{A} = \\left\\{ \\text{A}, \\text{R}, \\text{W} \\right\\}$, where:\n",
    "- A = \"accept the job offer\"\n",
    "- R = \"reject the job offer\"\n",
    "- W = \"work\" (when you don't need to take an action as you're not laid off)\n",
    "\n",
    "\n",
    "The transitions are:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbb{P}(S_t = i, A_t = W, S_{t + 1} = i) & = 1 - \\alpha \\\\ \n",
    "    \\mathbb{P}(S_t = i, A_t = W, S_{t + 1} = 0) & = \\alpha \\\\\n",
    "    \\mathbb{P}(S_t = 0, A_t = A, S_{t + 1} = i) & = 1 - \\alpha \\\\\n",
    "    \\mathbb{P}(S_t = 0, A_t = A, S_{t + 1} = 0) & = \\alpha\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $i$ is the job $i$ being offered when you're unemployed.\n",
    "\n",
    "The rewards are:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathcal{R}(S_t = i, A_t = W) & = \\log \\left( w_i \\right) \\\\  \n",
    "    \\mathcal{R}(S_t = 0, A_t = A) & = \\log \\left( w_i \\right) \\\\\n",
    "    \\mathcal{R}(S_t = 0, A_t = R) & = \\log \\left( w_0 \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $w_{i_u}$ is the wage earned per day from working job $i$ on day $u$ and $w_0$ is the unemployment wage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed728d",
   "metadata": {},
   "source": [
    "#### Question 2:       \n",
    "You can solve this Bellman Optimality Equation (hence, solve for the Optimal Value Function and the Optimal Policy) with a numerical iterative algorithm (essentially a Dynamic Programming algorithm customized to this problem). Write Python code for this numerical algorithm. Clearly define the inputs and outputs of your algorithm with their types (int, float, List, Mapping etc.). For this problem, don't use any of the MDP/DP code from the git repo, write this customized algorithm from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164faa97",
   "metadata": {},
   "source": [
    "The Bellman optimality equations become:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V_i^* & = \\log \\left( w_i \\right) + \\gamma * \\left[ \\alpha \\cdot V_0^* + (1 - \\alpha) * V_i^* \\right] \\\\ \n",
    "\\therefore V_i^* & = \\frac{\\log \\left( w_i \\right) + \\gamma \\cdot \\alpha \\cdot V_0^*}{1 - \\gamma * (1 - \\alpha)} \\\\ \\\\ \n",
    "\n",
    "Q(0, A) & = \\log \\left( w_i \\right) + \\gamma * \\left[ \\alpha \\cdot V_0^* + (1 - \\alpha) \\cdot V_i ^* \\right] \\\\\n",
    "Q(0, R) & = \\log \\left( w_0 \\right) + \\gamma * 1 \\cdot V_0^* \\\\ \n",
    "\\therefore V_0^* & = \\Sigma_{i = 1}^n p_i \\cdot \\max \\left\\{ \\log \\left( w_i \\right) + \\gamma * \\left[ \\alpha \\cdot V_0^* + (1 - \\alpha) \\cdot V_i ^* \\right], \\log \\left( w_0 \\right) + \\gamma * 1 \\cdot V_0^* \\right\\}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f17a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_jobs = 3\n",
    "wages = np.array([10.0, 9.0, 5.0])\n",
    "unemployment_wage = 8.0\n",
    "job_offer_probs = np.array([0.3, 0.5, 0.2])\n",
    "alpha = 0.1\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720e2f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.34041222, 22.7011649 , 22.14663587, 19.05302185])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_0 = np.zeros(num_jobs + 1)\n",
    "TOLERANCE = 1e-5\n",
    "MAX_ITER = 1_000\n",
    "num_iter = 0\n",
    "\n",
    "while num_iter < MAX_ITER:\n",
    "    v_1 = np.zeros(num_jobs + 1)\n",
    "    v_1[1:] = (np.log(wages) + gamma * alpha * v_0[0]) / (1.0 - gamma * (1.0 - alpha))\n",
    "\n",
    "    q_accept = np.log(wages) + gamma * (alpha * v_0[0] + (1.0 - alpha) * v_1[1:])\n",
    "    q_reject = np.log(unemployment_wage) + gamma * v_0[0]\n",
    "\n",
    "    # calculate expected future utilities from accepting/rejecting jobs\n",
    "    v_1[0] = np.sum(job_offer_probs * np.maximum(q_accept, q_reject))\n",
    "\n",
    "    if np.max(np.abs(v_1 - v_0)) < TOLERANCE:\n",
    "        v_0 = v_1\n",
    "        break\n",
    "\n",
    "    v_0 = v_1\n",
    "    num_iter += 1\n",
    "\n",
    "\n",
    "optimal_vf = v_1\n",
    "optimal_vf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac0469",
   "metadata": {},
   "source": [
    "### What is the optimal policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430db362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1:\n",
      "\tWages = $10.00\n",
      "\tExpected rewards of accepting = $22.701\n",
      "\tExpected rewards of rejecting = $22.186\n",
      "\tDecision = Accept\n",
      "\n",
      "Job 2:\n",
      "\tWages = $9.00\n",
      "\tExpected rewards of accepting = $22.147\n",
      "\tExpected rewards of rejecting = $22.186\n",
      "\tDecision = Reject\n",
      "\n",
      "Job 3:\n",
      "\tWages = $5.00\n",
      "\tExpected rewards of accepting = $19.053\n",
      "\tExpected rewards of rejecting = $22.186\n",
      "\tDecision = Reject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_accept_star = np.log(wages) + gamma * (\n",
    "    alpha * optimal_vf[0] + (1.0 - alpha) * optimal_vf[1:]\n",
    ")\n",
    "q_reject_star = np.log(unemployment_wage) + gamma * optimal_vf[0]\n",
    "\n",
    "optimal_policy = q_accept_star > q_reject_star\n",
    "\n",
    "# print out policy from the s = 0 state\n",
    "for i in range(num_jobs):\n",
    "    print(\n",
    "        f\"Job {i + 1}:\\n\\tWages = ${wages[i]:.2f}\\n\\t\"\n",
    "        f\"Expected rewards of accepting = ${q_accept_star[i]:.3f}\\n\\t\"\n",
    "        f\"Expected rewards of rejecting = ${q_reject_star:.3f}\\n\\t\"\n",
    "        f\"Decision = {'Accept' if optimal_policy[i] else 'Reject'}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c76da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-statistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
