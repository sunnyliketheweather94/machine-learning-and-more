{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b85c7bb",
   "metadata": {},
   "source": [
    "## Solving the Simple Inventory Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6ce1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(\".\"), os.pardir)))\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import scipy.stats as ss\n",
    "from pprint import pprint\n",
    "\n",
    "from rl.distributions import Categorical\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.policy import FiniteDeterministicPolicy\n",
    "from rl.dynamic_programming.policy_methods import (\n",
    "    evaluate_mrp_result,\n",
    "    policy_iteration_result,\n",
    ")\n",
    "from rl.dynamic_programming.value_methods import value_iteration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f44aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Inventory:\n",
    "    on_hand: int\n",
    "    on_order: int\n",
    "\n",
    "    @property\n",
    "    def total_inventory(self) -> str:\n",
    "        return self.on_hand + self.on_order\n",
    "\n",
    "\n",
    "class SimpleInventoryWithCapacityConstraintsMDP(\n",
    "    FiniteMarkovDecisionProcess[Inventory, int]\n",
    "):\n",
    "    def __init__(\n",
    "        self,\n",
    "        capacity: int,\n",
    "        poisson_lambda: float,\n",
    "        holding_costs: float,\n",
    "        stockout_costs: float,\n",
    "    ):\n",
    "        self.capacity: int = capacity\n",
    "        self.poisson_lambda: float = poisson_lambda\n",
    "        self.holding_costs: float = -holding_costs\n",
    "        self.stockout_costs: float = -stockout_costs\n",
    "        self.poisson_distr = ss.poisson(self.poisson_lambda)\n",
    "\n",
    "        super().__init__(self.generate_action_transition_reward_map())\n",
    "\n",
    "    def generate_action_transition_reward_map(\n",
    "        self,\n",
    "    ) -> dict[Inventory, dict[int, Categorical[tuple[Inventory, float]]]]:\n",
    "        dist: dict[Inventory, dict[int, Categorical[tuple[Inventory, float]]]] = dict()\n",
    "\n",
    "        for alpha in range(self.capacity + 1):\n",
    "            for beta in range(self.capacity + 1 - alpha):\n",
    "                state = Inventory(on_hand=alpha, on_order=beta)\n",
    "                total_inventory = state.total_inventory\n",
    "                base_reward: float = self.holding_costs * alpha\n",
    "                sub_dist: dict[int, Categorical[tuple[Inventory, float]]] = dict()\n",
    "\n",
    "                for order in range(self.capacity + 1 - total_inventory):\n",
    "                    next_state_reward_dist = {\n",
    "                        (\n",
    "                            Inventory(on_hand=total_inventory - demand, on_order=order),\n",
    "                            base_reward,\n",
    "                        ): self.poisson_distr.pmf(demand)\n",
    "                        for demand in range(total_inventory)\n",
    "                    }\n",
    "\n",
    "                    prob = 1.0 - self.poisson_distr.cdf(total_inventory - 1)\n",
    "                    reward = base_reward + self.stockout_costs * (\n",
    "                        self.poisson_lambda\n",
    "                        - total_inventory\n",
    "                        * (1 - self.poisson_distr.pmf(total_inventory) / prob)\n",
    "                    )\n",
    "\n",
    "                    next_state_reward_dist[\n",
    "                        (Inventory(on_hand=0, on_order=order), reward)\n",
    "                    ] = prob\n",
    "                    sub_dist[order] = Categorical(next_state_reward_dist)\n",
    "\n",
    "                dist[state] = sub_dist\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4cd8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = 2\n",
    "poisson_lambda = 1.0\n",
    "holding_costs = 1.0\n",
    "stockout_costs = 10.0\n",
    "\n",
    "si_mdp = SimpleInventoryWithCapacityConstraintsMDP(\n",
    "    capacity=capacity,\n",
    "    poisson_lambda=poisson_lambda,\n",
    "    holding_costs=holding_costs,\n",
    "    stockout_costs=stockout_costs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7112cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp = FiniteDeterministicPolicy(\n",
    "    {\n",
    "        Inventory(alpha, beta): capacity - (alpha + beta)\n",
    "        for alpha in range(capacity + 1)\n",
    "        for beta in range(capacity + 1 - alpha)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4395e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{NonTerminal(state=Inventory(on_hand=0, on_order=0)): np.float64(-43.59563313047814),\n",
      " NonTerminal(state=Inventory(on_hand=0, on_order=1)): np.float64(-37.971111794412636),\n",
      " NonTerminal(state=Inventory(on_hand=0, on_order=2)): np.float64(-37.32849043566549),\n",
      " NonTerminal(state=Inventory(on_hand=1, on_order=0)): np.float64(-38.971111794412636),\n",
      " NonTerminal(state=Inventory(on_hand=1, on_order=1)): np.float64(-38.32849043566549),\n",
      " NonTerminal(state=Inventory(on_hand=2, on_order=0)): np.float64(-39.32849043566549)}\n"
     ]
    }
   ],
   "source": [
    "implied_mrp = si_mdp.apply_finite_policy(fdp)\n",
    "pprint(evaluate_mrp_result(mrp=implied_mrp, gamma=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be971fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{NonTerminal(state=Inventory(on_hand=0, on_order=0)): np.float64(-43.59563313047814),\n",
      " NonTerminal(state=Inventory(on_hand=0, on_order=1)): np.float64(-37.971111794412636),\n",
      " NonTerminal(state=Inventory(on_hand=0, on_order=2)): np.float64(-37.32849043566549),\n",
      " NonTerminal(state=Inventory(on_hand=1, on_order=0)): np.float64(-38.971111794412636),\n",
      " NonTerminal(state=Inventory(on_hand=1, on_order=1)): np.float64(-38.32849043566549),\n",
      " NonTerminal(state=Inventory(on_hand=2, on_order=0)): np.float64(-39.32849043566549)}\n",
      "\n",
      "For State Inventory(on_hand=0, on_order=0): Do Action 2\n",
      "For State Inventory(on_hand=0, on_order=1): Do Action 1\n",
      "For State Inventory(on_hand=0, on_order=2): Do Action 0\n",
      "For State Inventory(on_hand=1, on_order=0): Do Action 1\n",
      "For State Inventory(on_hand=1, on_order=1): Do Action 0\n",
      "For State Inventory(on_hand=2, on_order=0): Do Action 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimal_vf, optimal_policy = policy_iteration_result(mdp=si_mdp, gamma=0.9)\n",
    "\n",
    "pprint(optimal_vf)\n",
    "print()\n",
    "print(optimal_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa45b846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{NonTerminal(state=Inventory(on_hand=0, on_order=0)): np.float64(-43.59563313047815),\n",
      " NonTerminal(state=Inventory(on_hand=0, on_order=1)): np.float64(-37.97111179441265),\n",
      " NonTerminal(state=Inventory(on_hand=0, on_order=2)): np.float64(-37.3284904356655),\n",
      " NonTerminal(state=Inventory(on_hand=1, on_order=0)): np.float64(-38.97111179441265),\n",
      " NonTerminal(state=Inventory(on_hand=1, on_order=1)): np.float64(-38.3284904356655),\n",
      " NonTerminal(state=Inventory(on_hand=2, on_order=0)): np.float64(-39.3284904356655)}\n",
      "\n",
      "For State Inventory(on_hand=0, on_order=0): Do Action 2\n",
      "For State Inventory(on_hand=0, on_order=1): Do Action 1\n",
      "For State Inventory(on_hand=0, on_order=2): Do Action 0\n",
      "For State Inventory(on_hand=1, on_order=0): Do Action 1\n",
      "For State Inventory(on_hand=1, on_order=1): Do Action 0\n",
      "For State Inventory(on_hand=2, on_order=0): Do Action 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimal_vf, optimal_policy = value_iteration_result(mdp=si_mdp, gamma=0.9)\n",
    "\n",
    "pprint(optimal_vf)\n",
    "print()\n",
    "print(optimal_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1804e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-statistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
